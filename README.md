# rag-stack
Deploy retrieval-augmented generation to chat your data with open-source LLMs like XGen, Falcon, and GPT4All


## Run locally

To run locally, you can use the GPT4All model, which runs on consumer hardware

1. Download [ggml-gpt4all-j-v1.3-groovy.bin](https://gpt4all.io/models/ggml-gpt4all-j-v1.3-groovy.bin) into `server/llm/local/`

## Credits

The code for containerizing Falcon 7B is from Het Trivedi's [tutorial repo](https://github.com/htrivedi99/falcon-7b-truss). Check out his Medium article on how to dockerize Falcon [here](https://towardsdatascience.com/deploying-falcon-7b-into-production-6dd28bb79373)!
